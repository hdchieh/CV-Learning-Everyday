# CV-Learning-Everyday

The README file mainly contains papers and related links.

The reading notes and summary of some papers will be published in the [***issue section***](https://github.com/huuuuusy/CV-Learning-Everyday/issues) and marked with different labels. You are welcome to discuss with me under the issue secion if you have interest in this paper.

## 1. Video

### [1.1 Dataset](https://github.com/huuuuusy/CV-Learning-Everyday/issues/3)

### [1.2 Method](https://github.com/huuuuusy/CV-Learning-Everyday/issues/4)

|List|
| :--: |
|[Classical methods](https://github.com/huuuuusy/CV-Learning-Everyday/issues/4#issuecomment-520127495)|
|[Frame-by-frame processing fusion](https://github.com/huuuuusy/CV-Learning-Everyday/issues/4#issuecomment-520127710)|
|[ConvLSTM](https://github.com/huuuuusy/CV-Learning-Everyday/issues/4#issuecomment-520127786)|
|[3D convolution](https://github.com/huuuuusy/CV-Learning-Everyday/issues/4#issuecomment-520127897)|
|[Two-stream](https://github.com/huuuuusy/CV-Learning-Everyday/issues/4#issuecomment-520127980)|
|[Reference](https://github.com/huuuuusy/CV-Learning-Everyday/issues/4#issuecomment-520128071)|

### 1.3 Task

|List|Part|
| :--: |:--: |
|[Multitask learning](https://github.com/huuuuusy/CV-Learning-Everyday/issues/5)|[【Paper】](https://github.com/huuuuusy/CV-Learning-Everyday/issues/5#issuecomment-520128862)[【Reference】](https://github.com/huuuuusy/CV-Learning-Everyday/issues/5#issuecomment-520128875)|
|[Video summarization](https://github.com/huuuuusy/CV-Learning-Everyday/issues/6)|[【Paper】](https://github.com/huuuuusy/CV-Learning-Everyday/issues/6#issuecomment-520129159)【Reference】(https://github.com/huuuuusy/CV-Learning-Everyday/issues/6#issuecomment-520129190)|
|[Video object detection](https://github.com/huuuuusy/CV-Learning-Everyday/issues/7)|[【Paper】](https://github.com/huuuuusy/CV-Learning-Everyday/issues/7#issuecomment-520129563)[【Reference】](https://github.com/huuuuusy/CV-Learning-Everyday/issues/7#issuecomment-520129587)|
|[Video prediction](https://github.com/huuuuusy/CV-Learning-Everyday/issues/8)|[【Paper】](https://github.com/huuuuusy/CV-Learning-Everyday/issues/8#issuecomment-520130004)[【Reference】](https://github.com/huuuuusy/CV-Learning-Everyday/issues/8#issuecomment-520130037)|
|[Video semantic segmentation](https://github.com/huuuuusy/CV-Learning-Everyday/issues/9)|[【Paper】](https://github.com/huuuuusy/CV-Learning-Everyday/issues/9#issuecomment-520130345)[【Reference】](https://github.com/huuuuusy/CV-Learning-Everyday/issues/9#issuecomment-520130352)|
|[Video caption](https://github.com/huuuuusy/CV-Learning-Everyday/issues/10)|[【Paper】](https://github.com/huuuuusy/CV-Learning-Everyday/issues/10#issuecomment-520130512)[【Reference】](https://github.com/huuuuusy/CV-Learning-Everyday/issues/10#issuecomment-520130537)|
|[Video generation (GAN)](https://github.com/huuuuusy/CV-Learning-Everyday/issues/11)|[【Paper】](https://github.com/huuuuusy/CV-Learning-Everyday/issues/11#issuecomment-520130652)|
|[Video saliency prediction](https://github.com/huuuuusy/CV-Learning-Everyday/issues/12)|[【Paper】](https://github.com/huuuuusy/CV-Learning-Everyday/issues/12#issuecomment-520130790)[【Reference】](https://github.com/huuuuusy/CV-Learning-Everyday/issues/12#issuecomment-520130803)|
|[Video pedestrian](https://github.com/huuuuusy/CV-Learning-Everyday/issues/13)|[【Paper】](https://github.com/huuuuusy/CV-Learning-Everyday/issues/13#issuecomment-520130951)[【Reference】](https://github.com/huuuuusy/CV-Learning-Everyday/issues/13#issuecomment-520130973)|
|[Video frame interpolation](https://github.com/huuuuusy/CV-Learning-Everyday/issues/14)|[【Paper】](https://github.com/huuuuusy/CV-Learning-Everyday/issues/14#issuecomment-520131227)[【Reference】](https://github.com/huuuuusy/CV-Learning-Everyday/issues/14#issuecomment-520131241)|
|[]()|[【Paper】]()[【Reference】]()|

#### [1.3.5 Video question answer & retrieval & search & reasoning](https://github.com/huuuuusy/CV-Learning-Everyday/blob/master/video-based/T006-Video%20question%20answer%20%26%20retrieval%20%26%20search%20%26%20reasoning.md)

|Paper|Extra Link|
| :--: |:--: |
|【CVPR'18】[Motion-Appearance Co-Memory Networks for Video Question Answering](https://arxiv.org/abs/1803.10906)||
|【CVPR'18 Oral】[Finding "It": Weakly-Supervised Reference-Aware Visual Grounding in Instructional Videos](http://openaccess.thecvf.com/content_cvpr_2018/papers/Huang_Finding_It_Weakly-Supervised_CVPR_2018_paper.pdf)|[【Project Page】](https://finding-it.github.io/)[【Blog(Chinese)】](https://zhuanlan.zhihu.com/p/36374060)|
|【CVPR'18】[Attend and Interact: Higher-Order Object Interactions for Video Understanding](https://arxiv.org/abs/1711.06330)|[【Blog(Chinese)】](https://blog.csdn.net/u014230646/article/details/80878109)|
|【CVPR'18】[MovieGraphs: Towards Understanding Human-Centric Situations from Videos](http://www.cs.toronto.edu/~makarand/papers/CVPR2018_MovieGraphs.pdf)|[【Project Page】](http://moviegraphs.cs.toronto.edu/)|

|Reference|
| :--: |
|【专知】[【论文推荐】最新7篇视觉问答（VQA）相关论文—解释、读写记忆网络、逆视觉问答、视觉推理、可解释性、注意力机制、计数](https://cloud.tencent.com/developer/article/1086325)|


#### [1.3.7 Video flow & depth & super-resolution](https://github.com/huuuuusy/CV-Learning-Everyday/blob/master/video-based/T008-Video%20flow%20%26%20depth%20%26%20super-resolution.md)

|Paper|Extra Link|
| :--: |:--: |
|【CVPR'18】[Frame-Recurrent Video Super-Resolution](https://arxiv.org/abs/1801.04590)|[【Project Page】](https://github.com/msmsajjadi/frvsr)[【Blog(Chinese)】](https://blog.csdn.net/qq_33590958/article/details/89654853)|
|【CVPR'18】[PoseFlow: A Deep Motion Representation for Understanding Human Behaviors in Videos](http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/3170.pdf)||
|【CVPR'18】[LEGO: Learning Edge with Geometry all at Once by Watching Videos](https://arxiv.org/abs/1803.05648)|[【Project Page】](https://github.com/zhenheny/LEGO)[【Blog(Chinese)】](https://zhuanlan.zhihu.com/p/50729039)|
|【CVPR'18】[Learning Depth from Monocular Videos using Direct Methods](https://arxiv.org/abs/1712.00175)|[【Project Page】](https://github.com/MightyChaos/LKVOLearner)[【Blog(Chinese)】](https://blog.csdn.net/yueleileili/article/details/82946910)|
|【CVPR'18】[End-to-End Learning of Motion Representation for Video Understanding](https://arxiv.org/abs/1804.00413)|[【Project Page】](https://github.com/LijieFan/tvnet)[【Blog(Chinese)】](https://blog.csdn.net/weixin_42164269/article/details/80651752)|
|【CVPR'18】[Unsupervised Learning of Depth and Ego-Motion from Monocular Video Using 3D Geometric Constraints](https://arxiv.org/abs/1802.05522)||

|Reference|
| :--: |
|【CSDN】[super resolution 论文阅读简略笔记](https://blog.csdn.net/Zealoe/article/details/78550444)|
|【CSDN】[深度学习（二十二）——ESPCN, FSRCNN, VESPCN, SRGAN, DemosaicNet, MemNet, RDN, ShuffleSeg](https://blog.csdn.net/antkillerfarm/article/details/79956241)|
|【CSDN】[CVPR2019中关于超分辨率算法的16篇论文](https://blog.csdn.net/leviopku/article/details/90634994)|
|【GitHub】[Video-Super-Resolution](https://github.com/flyywh/Video-Super-Resolution)|
|【GitHub】[Mind Mapping for Depth Estimation](https://github.com/sxfduter/monocular-depth-estimation)|
|【知乎】[CVPR2018 人体姿态相关](https://zhuanlan.zhihu.com/p/38328177)|
|【知乎】[深度学习在图像超分辨率重建中的应用](https://zhuanlan.zhihu.com/p/25532538)|

#### [1.3.8 Video classification & recognition](https://github.com/huuuuusy/CV-Learning-Everyday/blob/master/video-based/T009-Video%20classification%20%26%20recognition.md)

|Paper|Extra Link|
| :--: |:--: |
|【CVPR'18】[Appearance-and-Relation Networks for Video Classification](https://arxiv.org/abs/1711.09125)|[【Project Page】](https://github.com/wanglimin/ARTNet)[【Blog(Chinese)】](https://zhuanlan.zhihu.com/p/32197854)|
|【CVPR'18】[Recurrent Residual Module for Fast Inference in Videos](https://arxiv.org/abs/1802.09723)||
|【CVPR'18】[Memory Based Online Learning of Deep Representations from Video Streams](https://arxiv.org/abs/1711.07368)||
|【CVPR'18】[Geometry Guided Convolutional Neural Networks for Self-Supervised Video Representation Learning](https://cseweb.ucsd.edu/~haosu/papers/cvpr18_geometry_predictive_learning.pdf)||
|【CVPR'18】[Learning Latent Super-Events to Detect Multiple Activities in Videos](http://openaccess.thecvf.com/content_cvpr_2018/papers/Piergiovanni_Learning_Latent_Super-Events_CVPR_2018_paper.pdf)|[【Project Page】](https://github.com/piergiaj/super-events-cvpr18)|
|【CVPR'18】[Compressed Video Action Recognition](http://openaccess.thecvf.com/content_cvpr_2018/papers/Wu_Compressed_Video_Action_CVPR_2018_paper.pdf)|[【Project Page】](https://github.com/chaoyuaw/pytorch-coviar)[【Blog(Chinese)1】](https://blog.csdn.net/perfects110/article/details/84329491)[【Blog(Chinese)2】](https://blog.csdn.net/Dongjiuqing/article/details/84678962)|
|【CVPR'18】[Video Representation Learning Using Discriminative Pooling](http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Video_Representation_Learning_CVPR_2018_paper.pdf)|[【Project Page】](https://github.com/3xwangDot/SVMP)|
|【CVPR'18】[Optical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognition](https://arxiv.org/abs/1711.11152)|[【Project Page】](https://github.com/kevin-ssy/Optical-Flow-Guided-Feature)|
|【CVPR'18】[NeuralNetwork-Viterbi: A Framework for Weakly Supervised Video Learning Spotlight](https://arxiv.org/abs/1805.06875)|[【Project Page】](https://github.com/alexanderrichard/NeuralNetwork-Viterbi)|
|【CVPR'18】[Temporal Deformable Residual Networks for Action Segmentation in Videos](http://openaccess.thecvf.com/content_cvpr_2018/papers/Lei_Temporal_Deformable_Residual_CVPR_2018_paper.pdf)||

|Reference|
| :--: |
|【知乎】[简评Video Action Recognition 的近期进展](https://zhuanlan.zhihu.com/p/59915784)|
|【知乎】[Video Analysis相关领域解读之Action Recognition(行为识别)](https://zhuanlan.zhihu.com/p/26460437)|
|【CSDN】[3D CNN框架结构各层计算](https://blog.csdn.net/auto1993/article/details/70948249)|
|【CSDN】[Temporal Action Detection (时序动作检测)综述](https://blog.csdn.net/qq_33278461/article/details/80720104)|
